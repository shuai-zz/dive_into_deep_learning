{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0053b98",
   "metadata": {},
   "source": [
    "# 自动微分\n",
    "- 自动微分(automatic differentiation)：深度学习框架中自动计算导数的方法\n",
    "- 计算图(computational graph)：跟踪计算是哪些数据通过哪些组合操作产生输出\n",
    "- 反向传播(backpropagate)：跟踪整个computational graph，填充关于每个参数的偏导数\n",
    "  \n",
    "  实际中，根据设计好的模型，系统会构建一个computational graph，并且自动微分使系统能够随后反向传播梯度"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9cf1be",
   "metadata": {},
   "source": [
    "## 例子\n",
    "对于函数$y=2\\mathbf{X}^\\top \\mathbf{X}$关于列向量$\\mathbf{X}$求导"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43b0efd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 2., 3.])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建X并为其分配初始值\n",
    "import torch\n",
    "x=torch.arange(4.0)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01bf2896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 需要一个地方存储梯度，并且要在原地更改\n",
    "# 等价于x=torch.arange(4.0,requires_grad=True)  \n",
    "x.requires_grad_(True) \n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f83cf28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(28., grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 计算y\n",
    "y=2*torch.dot(x,x)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c580ba5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  4.,  8., 12.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 计算并打印梯度\n",
    "y.backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "598dadb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad==4*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74e61361",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 默认pytroch会积累梯度，需要清零\n",
    "x.grad.zero_()\n",
    "y=x.sum()\n",
    "y.backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f48196",
   "metadata": {},
   "source": [
    "## 非scalar变量的backpropogation\n",
    "- 当y不是scalar时，向量y关于向量x的导数是一个矩阵。对于高阶和高维的y和x，求导的结果可以是一个高阶tensor，即雅可比矩阵(Jacobian matrix)  \n",
    "    input: $ X_{n\\times 1}=\\begin{bmatrix}x_1\\\\x_2\\\\\\vdots\\\\x_n\\end{bmatrix}$,output: $ Y_{m\\times 1}=\\begin{bmatrix}y_1\\\\y_2\\\\y_3\\\\\\vdots\\\\y_m\\end{bmatrix}，其中每个y_i都是x_1,x_2,\\cdots,x_n的函数，即y_i=f(x_1,x_2,\\cdots,x_n)$  \n",
    "    则$Y关于X的Jacobian matrix是m\\times n的矩阵，且J_{ij}=\\frac{\\partial y_i}{\\partial x_j}$\n",
    "    $$\n",
    "    \\Rightarrow \n",
    "    \\mathbf{J}=\\begin{bmatrix}\n",
    "    \\frac{\\partial y_1}{\\partial x_1} & \\frac{\\partial y_1}{\\partial x_2} & \\cdots & \\frac{\\partial y_1}{\\partial x_n}\\\\\n",
    "    \\frac{\\partial y_2}{\\partial x_1} & \\frac{\\partial y_2}{\\partial x_2} & \\cdots & \\frac{\\partial y_2}{\\partial x_n}\\\\\n",
    "    \\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
    "    \\frac{\\partial y_m}{\\partial x_1} & \\frac{\\partial y_m}{\\partial x_2} & \\cdots & \\frac{\\partial y_m}{\\partial x_n}\n",
    "    \\end{bmatrix}\n",
    "    $$  \n",
    "\n",
    "    以下面公式为例:  \n",
    "    $$\n",
    "    y=x \\odot x=\\begin{bmatrix}x_1^2&x_2^2&x_3^2&x_4^2\\end{bmatrix}^\\top\n",
    "    \\Rightarrow\n",
    "    \\mathbf{J}=\\begin{bmatrix}\n",
    "    2x_1 & 0 & 0 & 0\\\\\n",
    "    0 & 2x_2 & 0 & 0\\\\\n",
    "    0 & 0 & 2x_3 & 0\\\\\n",
    "    0 & 0 & 0 & 2x_4\n",
    "    \\end{bmatrix}\n",
    "    =\\begin{bmatrix}\n",
    "    0&0&0&0\\\\\n",
    "    0&2&0&0\\\\\n",
    "    0&0&4&0\\\\\n",
    "    0&0&0&6\n",
    "    \\end{bmatrix}\n",
    "    $$\n",
    "\n",
    "- 但当调用向量的反向计算时，我们通常会试图计算一批训练样本中每个组成部分的损失函数的导数。 这里，我们的目的不是计算微分矩阵，而是单独计算批量中每个样本的偏导数之和。\n",
    "    也就是说，在深度学习中，我们结合**梯度加权**的逻辑，将雅可比矩阵转化为我们需要的梯度向量，以下面的公式为例：\n",
    "    $$ \n",
    "    L=y.sum()=x_1^2+x_2^2+x_3^2+x_4^2\n",
    "    \\Rightarrow\n",
    "    \\nabla L=\\begin{bmatrix}\\frac{\\partial L}{\\partial x_1}&\\frac{\\partial L}{\\partial x_2}&\\frac{\\partial L}{\\partial x_3}&\\frac{\\partial L}{\\partial x_4}\\end{bmatrix}^\\top\n",
    "    =\\begin{bmatrix}2x_1&2x_2&2x_3&2x_4\\end{bmatrix}^\\top=\\begin{bmatrix}0&2&4&6\\end{bmatrix}^\\top\n",
    "    $$\n",
    "- 也等于权重向量$\\mathbf{v} = [1,1,1,1]^T$与雅可比矩阵$\\mathbf{J}$相乘\n",
    "    $$\n",
    "    \\nabla y=\\begin{bmatrix}1&1&1&1\\end{bmatrix}\\cdot \\begin{bmatrix}\n",
    "    0&0&0&0\\\\\n",
    "    0&2&0&0\\\\\n",
    "    0&0&4&0\\\\\n",
    "    0&0&0&6\n",
    "    \\end{bmatrix}=\\begin{bmatrix}0&2&4&6\\end{bmatrix}\n",
    "    $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82ec054f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 2., 4., 6.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 非标量调用backward需要传入一个gradient参数，该参数指定微分函数关于self的梯度\n",
    "# 本例只想求偏导数的和，所以传递梯度1\n",
    "x.grad.zero_()\n",
    "y=x*x\n",
    "# 等价于y.backward(torch.ones(len(x)))\n",
    "y.sum().backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd950056",
   "metadata": {},
   "source": [
    "## 分离计算\n",
    "- 目的：将某些计算移动到computation graph之外。例如，$y=f(x), z=g(x,y)$，我们想计算z关于x的梯度，但是希望将y视为常数\n",
    "- 步骤：\n",
    "  1. 分离y得到u，其中u保留y的数值，但丢弃y关于x的computation graph信息\n",
    "  2. 计算$z=u\\times x$，再反向传播得到梯度\n",
    "- 示例对比：\n",
    "  1. 使用分离计算：\n",
    "   $$\n",
    "   y=x\\times x=\\begin{bmatrix}x_1^2&x_2^2&x_3^2&x_4^2\\end{bmatrix}^\\top, u=y  \n",
    "   \\Rightarrow\n",
    "   z=u\\times x=\\begin{bmatrix}u_1 x_1&u_2 x_2&u_3 x_3&u_4 x_4\\end{bmatrix}^\\top, (u_i=x_i^2)  \n",
    "   \\Rightarrow\n",
    "   \\nabla z=\\begin{bmatrix}u_1&u_2&u_3&u_4\\end{bmatrix}^\\top=\\begin{bmatrix}x_1^2&x_2^2&x_3^2&x_4^2\\end{bmatrix}^\\top\n",
    "   $$\n",
    "  2. 不使用分离计算：\n",
    "   $$\n",
    "   y=x\\times x=\\begin{bmatrix}x_1^2&x_2^2&x_3^2&x_4^2\\end{bmatrix}^\\top\n",
    "   \\Rightarrow\n",
    "   z=y\\times x=\\begin{bmatrix}y_1 x_1&y_2 x_2&y_3 x_3&y_4 x_4\\end{bmatrix}^\\top=\\begin{bmatrix}x_1^3&x_2^3&x_3^3&x_4^3\\end{bmatrix}^\\top\n",
    "   \\Rightarrow\n",
    "   \\nabla z=\\begin{bmatrix}3x_1^2&3x_2^2&3x_3^2&3x_4^2\\end{bmatrix}^\\top\n",
    "   $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71aab462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad.zero_()\n",
    "y=x*x\n",
    "u=y.detach()\n",
    "z=u*x\n",
    "\n",
    "z.backward(torch.ones(len(x)))\n",
    "x.grad==u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0fcf472c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 记录了y的计算结果，随后可以在y上调用反向传播，得到y=x*x的梯度\n",
    "x.grad.zero_()\n",
    "y.sum().backward()\n",
    "x.grad==2*x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef40f512",
   "metadata": {},
   "source": [
    "## Python控制流的梯度计算\n",
    "- 使用自动微分的好处：即使构建函数的computation graph需要通过Python控制流，我们仍可以计算得到的变量的梯度。\n",
    "### 代码解释\n",
    "- f(a)\n",
    "  1. b=a*2\n",
    "  2. while循环：只要b的模长（标量的模长等于绝对值）小于1000，将b*2，直到模长大于等于1000\n",
    "  3. 若b的和（标量的和即自身）大于0，则c=b，否则c=100*b\n",
    "  4. 也就是说，f(a)=k*a\n",
    "- a.grad\n",
    "  1. $\\frac{\\partial f(a)}{\\partial a}=k=\\frac{k*a}{a}=\\frac{b}{a}$\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cabad981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# while的迭代数取决于输入值a\n",
    "def f(a):\n",
    "    b=a*2\n",
    "    while b.norm()<1000:\n",
    "        b=b*2\n",
    "    if b.sum()>0:\n",
    "        c=b\n",
    "    else:\n",
    "        c=100*b\n",
    "    return c\n",
    "\n",
    "# 计算梯度\n",
    "a=torch.randn(size=(),requires_grad=True)\n",
    "d=f(a)\n",
    "d.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "31f9f2e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 对于任何a，存在某个常量标量k，使得f(a)=k*a，其中k的值取决于输入a，因此可用d/a验证梯度是否正确\n",
    "a.grad==d/a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b61d485",
   "metadata": {},
   "source": [
    "## 练习"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51d8167",
   "metadata": {},
   "source": [
    "### 为什么计算二阶导比一阶导开销更大\n",
    "计算量呈平方级增长、内存占用显著增加、算法复杂度更高"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da53fd9",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 运行反向传播函数后，立即再次运行它，发生什么\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43md\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/d2l/lib/python3.13/site-packages/torch/_tensor.py:625\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    615\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    616\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    617\u001b[39m         Tensor.backward,\n\u001b[32m    618\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    623\u001b[39m         inputs=inputs,\n\u001b[32m    624\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m625\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    626\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/d2l/lib/python3.13/site-packages/torch/autograd/__init__.py:354\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    349\u001b[39m     retain_graph = create_graph\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    353\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m354\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/d2l/lib/python3.13/site-packages/torch/autograd/graph.py:841\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    839\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    840\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m841\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    842\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    844\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    845\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mRuntimeError\u001b[39m: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward."
     ]
    }
   ],
   "source": [
    "# 运行反向传播函数后，立即再次运行它，发生什么\n",
    "# d.backward()\n",
    "#RuntimeError: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c7848fbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True],\n",
       "        [True, True, True, True],\n",
       "        [True, True, True, True],\n",
       "        [True, True, True, True]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 在控制流的例子中，我们计算d关于a的导数，如果将变量a更改为随机向量或矩阵，会发生什么？\n",
    "# d.grad.zero_()\n",
    "a=torch.randn(4,4,requires_grad=True)\n",
    "d=f(a)\n",
    "d.sum().backward()\n",
    "a.grad==d/a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3d7742b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "情况1：a = 2.0（正数，进入y=a³）\n",
      "y = 8.0\n",
      "梯度dy/da = 12.0（理论值：3a² = 12）\n",
      "\n",
      "情况2：a = -1.0（非正数，进入y=a²）\n",
      "y = 1.0\n",
      "梯度dy/da = -2.0（理论值：2a = -2）\n"
     ]
    }
   ],
   "source": [
    "# 重新设计一个求控制流梯度的例子，运行并分析结果\n",
    "\n",
    "# 定义含控制流的函数：根据输入a的符号进入不同分支\n",
    "def control_flow_func(a):\n",
    "    # 分支1：若a为正数，执行y = a^3\n",
    "    if a > 0:\n",
    "        y = a ** 3\n",
    "    # 分支2：若a为非正数，执行y = a^2\n",
    "    else:\n",
    "        y = a ** 2\n",
    "    return y\n",
    "\n",
    "# 测试两种输入情况（正数和非正数）\n",
    "# 情况1：a为正数（进入分支1）\n",
    "a1 = torch.tensor(2.0, requires_grad=True)\n",
    "y1 = control_flow_func(a1)\n",
    "y1.backward()  # 计算y1对a1的梯度\n",
    "print(f\"情况1：a = {a1.item()}（正数，进入y=a³）\")\n",
    "print(f\"y = {y1.item()}\")\n",
    "print(f\"梯度dy/da = {a1.grad.item()}（理论值：3a² = 12）\\n\")\n",
    "\n",
    "# 清空梯度，测试情况2\n",
    "a1.grad.zero_()\n",
    "\n",
    "# 情况2：a为负数（进入分支2）\n",
    "a2 = torch.tensor(-1.0, requires_grad=True)\n",
    "y2 = control_flow_func(a2)\n",
    "y2.backward()  # 计算y2对a2的梯度\n",
    "print(f\"情况2：a = {a2.item()}（非正数，进入y=a²）\")\n",
    "print(f\"y = {y2.item()}\")\n",
    "print(f\"梯度dy/da = {a2.grad.item()}（理论值：2a = -2）\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cb2b9e88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 350x250 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# f(x)=sin(x)，绘制f(x)和f'(x)图像，后者不使用f'(x)=cos(x)\n",
    "import numpy as np\n",
    "from matplotlib_inline import backend_inline\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "\n",
    "\n",
    "# 作图\n",
    "def use_svg_display():\n",
    "    \"\"\"使用svg格式在Jupyter中显示绘图\"\"\"\n",
    "    backend_inline.set_matplotlib_formats('svg')\n",
    "\n",
    "# 设置图表大小\n",
    "def set_figsize(figsize=(3.5, 2.5)):\n",
    "    \"\"\"设置matplotlib的图表大小\"\"\"    \n",
    "    use_svg_display\n",
    "    plt.rcParams['figure.figsize'] = figsize\n",
    "\n",
    "# 设置轴属性\n",
    "def set_axes(axes, xlabel, ylabel, xlim, ylim, xscale, yscale, legend):\n",
    "    \"\"\"设置matplotlib的轴属性\"\"\"\n",
    "    axes.set_xlabel(xlabel)\n",
    "    axes.set_ylabel(ylabel)\n",
    "    axes.set_xscale(xscale)\n",
    "    axes.set_yscale(yscale)\n",
    "    axes.set_xlim(xlim)\n",
    "    axes.set_ylim(ylim)\n",
    "    if legend: axes.legend(legend)\n",
    "    axes.grid()\n",
    "\n",
    "# 绘制多条线条\n",
    "def plot(X,Y=None,xlabel=None,ylabel=None,legend=None,xlim=None,ylim=None,xscale='linear',yscale='linear',fmts=('-','m--','g-.','r:'),figsize=(3.5,2.5),axes=None):\n",
    "    \"\"\"绘制数据点\"\"\"\n",
    "    if legend is None:\n",
    "        legend = []\n",
    "    set_figsize(figsize)\n",
    "    axes=axes if axes else plt.gca()\n",
    "    # 如果X有一个轴，输出True \n",
    "    def has_one_axis(X):\n",
    "        return (hasattr(X, \"ndim\") and X.ndim == 1 or isinstance(X, list)\n",
    "                and not hasattr(X[0], \"__len__\"))\n",
    "    if has_one_axis(X):\n",
    "        X = [X]\n",
    "    if Y is None:\n",
    "        X, Y = [[]] * len(X), X\n",
    "    elif has_one_axis(Y):\n",
    "        Y = [Y]\n",
    "    if len(X) != len(Y):\n",
    "        X = X * len(Y)\n",
    "    axes.cla()\n",
    "    for x, y, fmt in zip(X, Y, fmts):\n",
    "        if len(x):\n",
    "            axes.plot(x, y, fmt)\n",
    "        else:\n",
    "            axes.plot(y, fmt)\n",
    "    set_axes(axes, xlabel, ylabel, xlim, ylim, xscale, yscale, legend)\n",
    "\n",
    "def f(x):\n",
    "    return torch.sin(x)\n",
    "\n",
    "# 计算梯度\n",
    "x=torch.arange(0, math.pi, 0.1,requires_grad=True)\n",
    "y=f(x)\n",
    "y.sum().backward()\n",
    "\n",
    "# 转为numpy数据\n",
    "x_numpy=x.detach().numpy()#(0,3,0.1)\n",
    "y_numpy=y.detach().numpy()#sin(x)\n",
    "y_prime_numpy=x.grad.numpy()#cos(x)\n",
    "plot(x_numpy,[y_numpy,y_prime_numpy],'x','f(x)',legend=['f(x)',\"f'(x)\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
